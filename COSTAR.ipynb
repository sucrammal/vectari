{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtny+KF7su7CVIItQO7mGN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sucrammal/vectari/blob/main/COSTAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGNp0_496d4D",
        "outputId": "b5102392-336d-4cd8-be92-a8e09edf6904",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaKwD_u353eN",
        "outputId": "028b16cf-013f-4e5d-e90c-ba0b4d4bd20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKFmr5fQN9yn",
        "outputId": "45657d35-d4c7-4dac-81d5-5d0178882ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Installing collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVW-fFFA6O7u",
        "outputId": "b31915b1-0f28-4242-aa01-5cead537ce31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import ipdb\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import *\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Setting up API\n",
        "gpt_config = {\n",
        "    'model': 'gpt-4-vectari-1106preview',\n",
        "    'azure_endpoint': 'https://oai-vectari-eastus2.openai.azure.com/',\n",
        "    'api_key': userdata.get('openAPIKey'),\n",
        "    'api_version': '2023-12-01-preview'\n",
        "}\n",
        "\n",
        "# gpt_config = {\n",
        "#     'model': 'gpt-35-turbo',\n",
        "#     'azure_endpoint': 'https://oai-vectari-northcentral-us.openai.azure.com/',\n",
        "#     'api_key': userdata.get('openAPIKey3.5'),\n",
        "#     'api_version': '2024-02-15-preview'\n",
        "# }\n",
        "\n",
        "print(gpt_config['azure_endpoint'])\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = gpt_config['azure_endpoint'],\n",
        "  api_key = gpt_config['api_key'],\n",
        "  api_version = gpt_config['api_version']\n",
        ")"
      ],
      "metadata": {
        "id": "09Fss_ip3L50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9a9f56-209a-4875-e7d0-89fdb722db10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://oai-vectari-eastus2.openai.azure.com/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "MeZv1DIs-Cgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate input file from scratch.\n",
        "input_file = input(\"Enter file path of raw dataset\")\n",
        "with open(input_file, 'r') as file:\n",
        "  all_complaints = pd.read_csv(file)\n",
        "\n",
        "# extract complaints with transcripts\n",
        "complaints_with_transcripts = all_complaints.loc[all_complaints[\"Consumer complaint narrative\"].notna()]\n",
        "complaints_with_transcripts.shape[0]"
      ],
      "metadata": {
        "id": "VsjHta14-CSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load LLM pre-cleaned transcripts from csv\n",
        "input_file = input(\"Enter a file name that exists in the Data folder: \")\n",
        "cleaned_dataset = pd.DataFrame()\n",
        "\n",
        "with open(input_file, 'r') as file:\n",
        "    cleaned_dataset = pd.read_csv(file)"
      ],
      "metadata": {
        "id": "H-uT4cSc-VIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8932b38f-42ba-4f4f-fb3d-fabaa7f666e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a file name that exists in the Data folder: /content/drive/MyDrive/Internships and Work/Summer 2024/Vectari/out/LLM_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This function uses the LLM to clean incoming transcripts**"
      ],
      "metadata": {
        "id": "1Wu4dg3_4-3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaning_system = \"\"\"\n",
        "CONTEXT: You will receive a transcript of a phone call between a call center agent at a mortgage servicing company and a customer/borrower. You need to clean this transcript.\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE: Your first job is to clean the incoming low-quality transcripts from the first dataset. These are calls about financial services and we have seen some text completely out of place.  For instance 'the first drug was fixed, and any drug after that was gonna be viral' should pretty clearly be\n",
        "'the first rate was fixed, and any rate after that was going to be variable'.\n",
        "Your job is to parse the text and using your natural language understanding and contextual awareness, please re-write the transcript and clean any grammar / things that do not make sense in financial use cases.\n",
        "Additionally, remove any unwanted 'x's, 'xxxx's, any other similar phrases representing redaction, and simply any text or numbers that aren't words. Remove any dates, names, and otherwise sensitive information. After the response is generated, remove all full stops, commas, semicolons, colons, and quotation marks.\n",
        "\n",
        "#############\n",
        "\n",
        "# STYLE #\n",
        "Financial complaint transcript\n",
        "\n",
        "#############\n",
        "\n",
        "# TONE #\n",
        "Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "# AUDIENCE #\n",
        "Banks. I want accurate classification so that they will adopt this methodology to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "# RESPONSE: A PARAGRAPH OF TEXT #\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aNj7O92w2_o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then, applying the cleaning function, ask the LLM to cluster the data**"
      ],
      "metadata": {
        "id": "szbm2_Sq5D9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_transcript(transcript):\n",
        "  messages = [\n",
        "    {\n",
        "        \"role\":\"system\",\n",
        "        \"content\": cleaning_system\n",
        "    },\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\":f'\"\"\"{transcript}\"\"\"'\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=gpt_config['model'],\n",
        "      messages = messages\n",
        "  )\n",
        "\n",
        "  LLM_cleaned_sample = response.choices[0].message.content\n",
        "  return LLM_cleaned_sample"
      ],
      "metadata": {
        "id": "mqOHWXUp7faM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_system = \"\"\"\n",
        "CONTEXT: You will now be recieving a large text containing transcripts of phone calls between a call center agent at a mortgage servicing company and a customer/borrower. This large text represents a CLUSTER of transcripts that have been categorized based on content under some label, for example, \"fraud or scam\".\n",
        "This label, referred to as the [OFFICIAL_CATEGORY_NAME], will be at the top of the inputted prompt before the transcripts. After a newline character, individual transcripts will be consecutively shown, separated by two newline characters from one another.\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE:\n",
        "Based on the cluster you have received,\n",
        "OFFICIAL CATEGORY NAME: Restate the OFFICIAL_CATEGORY_NAME given on the top of the inputted large text.\n",
        "CLUSTER_INFORMATION: Describe the cluster based on the content of the transcript data.\n",
        "\n",
        "#############\n",
        "\n",
        "STYLE:\n",
        "Business analytics report\n",
        "\n",
        "#############\n",
        "\n",
        "TONE:\n",
        "Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "AUDIENCE:\n",
        "Banks. I want to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "RESPONSE: MARKDOWN REPORT FORMATED IN THE FOLLOWING STYLE:\n",
        "– Offical name: [OFFICIAL_CATEGORY_NAME]\n",
        "— Complaint Group Profile: [CLUSTER_INFORMATION]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pmH3w5Y85xoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_complaints(cleaned_dataset):\n",
        "    clusters = cleaned_dataset.groupby('Issue')\n",
        "    cluster_info = {}\n",
        "\n",
        "    for label, group in tqdm(clusters, desc=\"Creating clusters\"):\n",
        "        # Collect all transcripts in this cluster\n",
        "        transcripts = group['Consumer complaint narrative'].tolist()\n",
        "\n",
        "        # Weird error. Passing the full, unsplit dataset through this function worked.\n",
        "        # But, passing a train set (from train_test_split) would crash since a value in transcripts would somehow not be a string.\n",
        "        filtered_list = [s for s in transcripts if isinstance(s, str)]\n",
        "\n",
        "        # Extract keywords and name cluster group.\n",
        "        all_transcripts_joined = \"\\n\\n\".join(filtered_list)\n",
        "        messages = [\n",
        "          {\n",
        "              \"role\":\"system\",\n",
        "              \"content\": cluster_system\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\":f'\"\"\" Official name: {label} \\n Transcrips: \\n {all_transcripts_joined}\"\"\"'\n",
        "          }\n",
        "        ]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=gpt_config['model'],\n",
        "            messages = messages\n",
        "        )\n",
        "\n",
        "        cluster_report = response.choices[0].message.content\n",
        "\n",
        "\n",
        "        cluster_info[label] = cluster_report\n",
        "\n",
        "    return cluster_info"
      ],
      "metadata": {
        "id": "ujtjZ2BX7pnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_system = \"\"\"\n",
        "CONTEXT: You have previously created Complaint Groups of transcripts of complaint phone calls between a call center agent at a mortgage servicing company and a customer/borrower based\n",
        "on the category of the complaints. Transcripts under each Complaint Group has been categorized based on content under some label, for example, \"fraud or scam\".\n",
        "\n",
        "You will now be recieving three things: the first is a set of markdown reports representing the information you have gathered and organized for each CLUSTER, and are of the following format:\n",
        "\"– Offical name: [OFFICIAL_CATEGORY_NAME]\n",
        "— Complaint Group Profile: [CLUSTER_INFORMATION]\"\n",
        "Each markdown report for each Complaint Group will be separated by a new line character, \"\\n\".\n",
        "\n",
        "The second piece of data you will receive is a transcript that has not been categorized into one of your CLUSTERs yet.\n",
        "\n",
        "The third piece of data you will receive is a comma-separated list of [OFFICIAL_CATEGORY_NAME]'s, representing all possible categories that the aformentioned transcript can belong to.\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE: Based on your natural language understanding, and your understanding of the cluster markdown reports, determine which [OFFICIAL_CATEGORY_NAME] from the list, the incoming transcript belongs under.\n",
        "\n",
        "#############\n",
        "\n",
        "STYLE: Business analytics report\n",
        "\n",
        "#############\n",
        "\n",
        "TONE: Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "AUDIENCE: Banks. I want accurate classification so that they will adopt this methodology to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "# RESPONSE: Single line of text containing ONLY one [OFFICIAL_CATEGORY_NAME] of your choosing from the comma-separated category name list: #\n",
        "[OFFICIAL_CATEGORY_NAME]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O_BO47O8AlNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_transcript(cluster_info, new_transcript):\n",
        "  # unpack official label names,\n",
        "  labels = cluster_info.keys()\n",
        "\n",
        "  # Join the keys into a string separated by commas\n",
        "  labels_string = ', '.join(labels)\n",
        "\n",
        "  # unpack and format cluster_info, aka the reports\n",
        "  markdown_reports = \"\"\n",
        "\n",
        "  for report in cluster_info.values():\n",
        "    markdown_reports = \"\\n\".join(report)\n",
        "\n",
        "  messages = [\n",
        "          {\n",
        "              \"role\":\"system\",\n",
        "              \"content\": classify_system\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\":f'\"\"\"Cluster markdown reports: \\n {markdown_reports} \\n Transcript to-be classified: \\n {new_transcript} \\n Category list: \\n {labels_string}\"\"\"'\n",
        "          }\n",
        "        ]\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "            model=gpt_config['model'],\n",
        "            messages = messages\n",
        "        )\n",
        "\n",
        "  complaint_label = response.choices[0].message.content\n",
        "\n",
        "  return complaint_label\n"
      ],
      "metadata": {
        "id": "5oSp54t68EXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to clean transcipts from scratch.\n",
        "LLM_cleaned_sentences = []\n",
        "all_labels = complaints_with_transcripts['Issue']\n",
        "\n",
        "# First, LLM cleanup\n",
        "tqdm.pandas(desc=\"LLM transcript cleaning\")\n",
        "LLM_cleaned_sentences = complaints_with_transcripts[\"Consumer complaint narrative\"].progress_apply(lambda x : clean_transcript(x))\n",
        "\n",
        "cleaned_dataset = pd.DataFrame({'Consumer complaint narrative': LLM_cleaned_sentences, 'Issue': all_labels})"
      ],
      "metadata": {
        "id": "uFBPt9kM3RQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-test split before clustering**"
      ],
      "metadata": {
        "id": "9Ku67Is_GZB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = train_test_split(cleaned_dataset, random_state=104, test_size=0.20, shuffle = True)"
      ],
      "metadata": {
        "id": "dsVBRpAwGcuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_info = cluster_complaints(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHDv78CW0RQF",
        "outputId": "60db7bfd-9971-4c88-e737-6677aff9ebd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating clusters: 100%|██████████| 6/6 [02:47<00:00, 27.98s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cluster_info.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9j1ISym1L31",
        "outputId": "ae9a6a2f-ef8d-456b-b127-de39a5af34c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['Fraud or scam', 'Incorrect/missing disclosures or info', 'Money was not available when promised', 'Other service issues', 'Other transaction issues', 'Wrong amount charged or received'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: export cluster data to a file.\n",
        "import json\n",
        "\n",
        "# Convert dictionary to a string\n",
        "dict_string = json.dumps(cluster_info, indent=4)\n",
        "\n",
        "# Write the string to a file\n",
        "with open('cluster_info.txt', 'w') as file:\n",
        "    file.write(dict_string)\n",
        "\n",
        "!cp cluster_info.txt \"/content/drive/MyDrive/Internships and Work/Summer 2024/Vectari/out\""
      ],
      "metadata": {
        "id": "ugb2ZjE4XIVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset.iloc[0])\n",
        "classify_transcript(cluster_info, test_dataset.iloc[0]['Consumer complaint narrative'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "kMX63TdQ8Oca",
        "outputId": "16344742-3d22-4f19-8405-997fe923d5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consumer complaint narrative    On XXXX/XXXX/15, I initiated a money transfer ...\n",
            "Issue                                                    Other transaction issues\n",
            "Name: 963, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wrong amount charged or received'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = []\n",
        "for transcript in tqdm(test_dataset['Consumer complaint narrative'], desc=\"Predicting labels\"):\n",
        "    predicted_labels.append(classify_transcript(cluster_info, transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8aqSDVo5fV",
        "outputId": "1a227d0a-caee-4e75-ade4-5907f607313d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting labels: 100%|██████████| 300/300 [31:28<00:00,  6.29s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_dataset['Issue'].tolist()\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(test_labels, predicted_labels))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(test_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzBDeQloq-jH",
        "outputId": "2b9f3cb6-c5c9-4cf0-b248-37c5b840ae4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.25333333333333335\n",
            "\n",
            "Classification Report:\n",
            "                                        precision    recall  f1-score   support\n",
            "\n",
            "                        Fraud or scam       0.83      0.55      0.66       115\n",
            "Incorrect/missing disclosures or info       0.00      0.00      0.00        11\n",
            "Money was not available when promised       0.00      0.00      0.00        44\n",
            "                 Other service issues       0.00      0.00      0.00        25\n",
            "             Other transaction issues       0.00      0.00      0.00        92\n",
            "     Wrong amount charged or received       0.06      1.00      0.11        13\n",
            "\n",
            "                             accuracy                           0.25       300\n",
            "                            macro avg       0.15      0.26      0.13       300\n",
            "                         weighted avg       0.32      0.25      0.26       300\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoqbOcHs11z5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}