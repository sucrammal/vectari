{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhWkeNxd3E0GnYvpO3tw7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sucrammal/vectari/blob/main/COSTAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGNp0_496d4D",
        "outputId": "7e112a6b-a1c0-4cf8-88d1-bac16598f20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVW-fFFA6O7u",
        "outputId": "eb07dfda-8539-47bf-ea60-4f2705ffaafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import *\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Setting up API\n",
        "gpt_config = {\n",
        "    'model': 'gpt-4-vectari-1106preview',\n",
        "    'azure_endpoint': 'https://oai-vectari-eastus2.openai.azure.com/',\n",
        "    'api_key': userdata.get('openAPIKey'),\n",
        "    'api_version': '2023-12-01-preview'\n",
        "}\n",
        "\n",
        "# gpt_config = {\n",
        "#     'model': 'gpt-35-turbo',\n",
        "#     'azure_endpoint': 'https://oai-vectari-northcentral-us.openai.azure.com/',\n",
        "#     'api_key': userdata.get('openAPIKey3.5'),\n",
        "#     'api_version': '2024-02-15-preview'\n",
        "# }\n",
        "\n",
        "print(gpt_config['azure_endpoint'])\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = gpt_config['azure_endpoint'],\n",
        "  api_key = gpt_config['api_key'],\n",
        "  api_version = gpt_config['api_version']\n",
        ")"
      ],
      "metadata": {
        "id": "09Fss_ip3L50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "MeZv1DIs-Cgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate input file from scratch.\n",
        "all_complaints = pd.read_csv(\"/content/drive/MyDrive/Internships and Work/Summer 2024/Vectari/data/money_transfer_complaints.csv\")\n",
        "\n",
        "# extract complaints with transcripts\n",
        "complaints_with_transcripts = all_complaints.loc[all_complaints[\"Consumer complaint narrative\"].notna()]\n",
        "complaints_with_transcripts.shape[0]"
      ],
      "metadata": {
        "id": "VsjHta14-CSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load LLM pre-cleaned transcripts from csv\n",
        "input_file = input(\"Enter a file name that exists in the Data folder: \")\n",
        "cleaned_dataset = pd.DataFrame()\n",
        "\n",
        "with open(input_file, 'r') as file:\n",
        "    cleaned_dataset = pd.read_csv(file)"
      ],
      "metadata": {
        "id": "H-uT4cSc-VIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This function uses the LLM to clean incoming transcripts**"
      ],
      "metadata": {
        "id": "1Wu4dg3_4-3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaning_system = \"\"\"\n",
        "CONTEXT: You will receive a transcript of a phone call between a call center agent at a mortgage servicing company and a customer/borrower. You need to clean this transcript.\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE: Your first job is to clean the incoming low-quality transcripts from the first dataset. These are calls about financial services and we have seen some text completely out of place.  For instance 'the first drug was fixed, and any drug after that was gonna be viral' should pretty clearly be\n",
        "'the first rate was fixed, and any rate after that was going to be variable'.\n",
        "Your job is to parse the text and using your natural language understanding and contextual awareness, please re-write the transcript and clean any grammar / things that do not make sense in financial use cases.\n",
        "Additionally, remove any unwanted 'x's, 'xxxx's, any other similar phrases representing redaction, and simply any text or numbers that aren't words. Remove any dates, names, and otherwise sensitive information. After the response is generated, remove all full stops, commas, semicolons, colons, and quotation marks.\n",
        "\n",
        "#############\n",
        "\n",
        "# STYLE #\n",
        "Financial complaint transcript\n",
        "\n",
        "#############\n",
        "\n",
        "# TONE #\n",
        "Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "# AUDIENCE #\n",
        "Banks. I want accurate classification so that they will adopt this methodology to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "# RESPONSE: A PARAGRAPH OF TEXT #\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aNj7O92w2_o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then, applying the cleaning function, ask the LLM to cluster the data**"
      ],
      "metadata": {
        "id": "szbm2_Sq5D9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_transcript(transcript):\n",
        "  messages = [\n",
        "    {\n",
        "        \"role\":\"system\",\n",
        "        \"content\": cleaning_system\n",
        "    },\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\":f'\"\"\"{transcript}\"\"\"'\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=gpt_config['model'],\n",
        "      messages = messages\n",
        "  )\n",
        "\n",
        "  LLM_cleaned_sample = response.choices[0].message.content\n",
        "  return LLM_cleaned_sample"
      ],
      "metadata": {
        "id": "mqOHWXUp7faM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_system = \"\"\"\n",
        "CONTEXT: You will now be recieving a large text containing transcripts of phone calls between a call center agent at a mortgage servicing company and a customer/borrower. Individual transcripts\n",
        "are separated by two newline characters, \"\\n\\n\", from one another. This large text represents a CLUSTER of transcripts that have been categorized based on content under some label, for example, \"fraud or scam\".\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE:\n",
        "Based on the cluster you have received,\n",
        "1. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\n",
        "2. CLUSTER_CATEGORY_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the category of the transcripts in this cluster.\n",
        "\n",
        "#############\n",
        "\n",
        "# STYLE #\n",
        "Business analytics report\n",
        "\n",
        "#############\n",
        "\n",
        "# TONE #\n",
        "Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "# AUDIENCE #\n",
        "Banks. I want accurate classification so that they will adopt this methodology to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "# RESPONSE: MARKDOWN REPORT #\n",
        "<From processing the CLUSTER you have received]>\n",
        "– Complaint Group: [CLUSTER_CATEGORY_NAME]\n",
        "— Complaint Group Profile: [CLUSTER_INFORMATION]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pmH3w5Y85xoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_complaints(df):\n",
        "    clusters = df.groupby('Issue')\n",
        "    cluster_info = {}\n",
        "\n",
        "    for label, group in clusters:\n",
        "        # Collect all transcripts in this cluster\n",
        "        transcripts = group['Customer complaint narrative'].apply(clean_transcript).tolist()\n",
        "\n",
        "        # Extract keywords and name cluster group.\n",
        "        all_transcripts_joined = '\\n\\n'.join(transcripts)\n",
        "\n",
        "        messages = [\n",
        "          {\n",
        "              \"role\":\"system\",\n",
        "              \"content\": cluster_system\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\":f'\"\"\"{all_transcripts_joined}\"\"\"'\n",
        "          }\n",
        "        ]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=gpt_config['model'],\n",
        "            messages = messages\n",
        "        )\n",
        "\n",
        "        cluster_report = response.choices[0].message.content\n",
        "\n",
        "\n",
        "        cluster_info[label] = {\n",
        "            'Report': cluster_report\n",
        "        }\n",
        "\n",
        "    return cluster_info"
      ],
      "metadata": {
        "id": "ujtjZ2BX7pnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_system = \"\"\"\n",
        "CONTEXT: You have previously created Complaint Groups of transcripts of complaint phone calls between a call center agent at a mortgage servicing company and a customer/borrower based\n",
        "on the category of the complaints. Transcripts under each Complaint Group has been categorized based on content under some label, for example, \"fraud or scam\".\n",
        "\n",
        "You will now be recieving two things: the first is a set of markdown reports representing the information you have gathered and organized for each CLUSTER, and are of the following format:\n",
        "\"– Complaint Group: [CLUSTER_CATEGORY_NAME]\n",
        "— Complaint Group Profile: [CLUSTER_INFORMATION]\"\n",
        "Each markdown report for each Complaint Group will be separated by a new line character \"\\n\".\n",
        "\n",
        "The second piece of data you will receive is a transcript that has not been categorized into one of your CLUSTERs yet.\n",
        "\n",
        "#############\n",
        "\n",
        "OBJECTIVE: Based on your natural language understanding, and your understanding of the read and determine which Complaint Group, the incoming transcript belongs under.\n",
        "\n",
        "#############\n",
        "\n",
        "# STYLE #\n",
        "Business analytics report\n",
        "\n",
        "#############\n",
        "\n",
        "# TONE #\n",
        "Professional, technical\n",
        "\n",
        "#############\n",
        "\n",
        "# AUDIENCE #\n",
        "Banks. I want accurate classification so that they will adopt this methodology to help organize their complaints database.\n",
        "\n",
        "#############\n",
        "\n",
        "# RESPONSE: Single line of text containing ONLY one [CLUSTER_CATEGORY_NAME] of your choosing. #\n",
        "[CLUSTER_CATEGORY_NAME]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O_BO47O8AlNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_transcripts(cluster_info, new_transcript):\n",
        "\n",
        "  # unpack and format cluster_info, aka the reports\n",
        "  markdown_reports = \"\"\n",
        "\n",
        "  messages = [\n",
        "          {\n",
        "              \"role\":\"system\",\n",
        "              \"content\": classify_system\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\":f'\"\"\"{markdown_reports} \\n {new_transcript}\"\"\"'\n",
        "          }\n",
        "        ]\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "            model=gpt_config['model'],\n",
        "            messages = messages\n",
        "        )\n",
        "\n",
        "  complaint_label = response.choices[0].message.content\n",
        "\n",
        "  return complaint_label\n",
        ""
      ],
      "metadata": {
        "id": "5oSp54t68EXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ky82AlbB8IWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}